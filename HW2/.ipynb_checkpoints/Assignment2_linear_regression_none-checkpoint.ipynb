{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7mwFWzhux0J"
   },
   "source": [
    "# Programming Assignment 2: Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGL2CVVeux0J"
   },
   "source": [
    "As we know, the COVID-19 pandemic has been disrupting people's life around the world. To get it under control, a crucial aspect is to be able to accurate forecast the spread of the disease, which can be helpful as a planning tool for policymakers, clinicians, and public health officers to deal with this crisis. In this notebook,we will try to do some forecasting on the covid-19 epidemic progression using machine learning. We will use a dataset based on the COVID-19 Data Repository at John Hopkins university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oPSazMP4ux0K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from math import sqrt \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXqNTB03ux0O"
   },
   "source": [
    "First, let us load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "QsFsOYRTux0O",
    "outputId": "6f037511-0d17-42dc-d6aa-9982365d1f74"
   },
   "outputs": [],
   "source": [
    "data_orig = pd.read_csv(\"us_covid_data.csv\")\n",
    "data = data_orig.copy()\n",
    "print (data_orig.columns)\n",
    "data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the date format\n",
    "dates = data['date']\n",
    "date_format = [pd.to_datetime(d) for d in dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fm30YZRHux0U"
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlyWWlKOux0V"
   },
   "source": [
    "**Task P1:** complete the following **three** visualization graphs that show the trend of the epidemic progression. Copy them to the solution file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 1: plot the total number of people tested for the entire period of the dataset. Your X axis will be the dates (\"Dates\") and Y-axis will be the total number of cases (\"People_tested\") over the period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "bXceVTTVux0V",
    "outputId": "d9cd606d-54fb-47ef-b891-501c7a23eaf9"
   },
   "outputs": [],
   "source": [
    "# Add code to plot the trend of the total number of people being tested as days progressed.\n",
    "# X axis -> dates('Dates')\n",
    "# Y axis -> number of people tested.('People_tested')\n",
    "\n",
    "### STUDENT: Start of Code ###\n",
    "\n",
    "\n",
    "### End of code ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 2: plot the total number of deaths for the entire period. Your X axis will be the dates (\"Dates\") and Y-axis will be the total number of death cases(\"Deaths\") over the period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "9cadesV1ux0Y",
    "outputId": "eae2507a-be85-419f-ba63-58a7981a175d"
   },
   "outputs": [],
   "source": [
    "# Add code to plot the trend of total deaths as days progressed.\n",
    "# X axis -> dates ('Dates')\n",
    "# Y axis -> number of deaths ('Deaths')\n",
    "\n",
    "\n",
    "### STUDENT: Start of Code ###\n",
    "\n",
    "\n",
    "### End of code ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDJ857lvux0b"
   },
   "source": [
    "Graph 3: plot the total number of infected cases for the entire period. Your X axis will be the dates (\"Dates\") and Y-axis will be the total number of infected cases ('New_positive_cases') over the period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "OAjc8x6Gux0e",
    "outputId": "f4a9b191-d089-4465-bef1-74629bc22bca"
   },
   "outputs": [],
   "source": [
    "### STUDENT: Start of Code ###\n",
    "\n",
    "\n",
    "\n",
    "### End of code ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that our data has different ranges of values for every feature and this can cause problems in our model, so here we will normalize our data (ignoring the categorical variables) so that our data is scaled between 0 and 1. The downside, however, is that the numbers are no longer interpretable. To interpret it, you need to multiply back by the scaling factor.\n",
    "\n",
    "**IMPORTANT: ** From now on, we will work with the normalized features to build the regression model. However, in **Task P8**, you need to convert the number back to the actual units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = data_orig.columns.values.tolist()\n",
    "\n",
    "for i in data_list[-11:]:\n",
    "    data[[i]]=(data_orig[i]-data_orig[i].min())/(data_orig[i].max()-data_orig[i].min())\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQAJGhQNux0g"
   },
   "source": [
    "# Calculate the feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkjaoLuGux0h"
   },
   "source": [
    "The following is a function that accepts a list of feature names (e.g. ['Total_Hospitalized', 'People_tested']) and an target feature e.g. ('Deaths') and returns two things:\n",
    "\n",
    "1. A numpy matrix whose columns are the desired features plus a column with a constant value 1, which is also known as the 'intercept'.\n",
    "2. A numpy array that contains the values of the target output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RXJqm-8oux0i"
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_frame, features, output):\n",
    "    # Steps\n",
    "    # select the columns of data_Frame given by the features list into the variable features_sframe which will include the constant\n",
    "    # Convert the features_frame into a numpy matrix\n",
    "    # assign the column of data_frame associated with the output to the array output_array\n",
    "    # convert the array into a numpy array by first converting it to a list\n",
    "    # return feature_matrix,output_array\n",
    "    \n",
    "    data_frame['constant'] = 1 # here we are adding a constant column \n",
    "    # add the column 'constant' to the front of the features list.\n",
    "    features = ['constant'] + features \n",
    "        \n",
    "    # select the columns of data_Frame given by the features list into the variable features_sframe which will include the constant)\n",
    "    features_frame = data_frame[features]\n",
    "    \n",
    "    # Convert the features_frame into a numpy matrix\n",
    "    feature_matrix = features_frame.to_numpy()\n",
    "    # print (\"feature_matrix:\", feature_matrix)\n",
    "    \n",
    "    # assign the column of data_frame associated with the output to the array output_array\n",
    "    output_array = data_frame[output]\n",
    "    \n",
    "    # convert the array into a numpy array by first converting it to a list\n",
    "    output_array = output_array.to_numpy()\n",
    "    \n",
    "    return(feature_matrix, output_array)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dates, we need to convert them into a sequence of numbers. We now add a new column to our dataframe corresponding to the number of days since the start of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = date_format\n",
    "day_numbers = []\n",
    "for i in range(1, len(X) + 1):\n",
    "    day_numbers.append([i])\n",
    "    \n",
    "data['Days'] = pd.DataFrame(day_numbers,columns = ['Days'])\n",
    "data[\"Days\"] = data[\"Days\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the above function for a particular input and output feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "po3KtihNux0k",
    "outputId": "15bce6d6-1a80-4c6c-f2d3-d39fc0270024"
   },
   "outputs": [],
   "source": [
    "(example_features, example_output) = get_numpy_data(data, ['Days'], 'New_positive_cases')\n",
    "print (example_features[0,:]) \n",
    "print (example_output[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the outputs with given regression weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had the weights $[1, 1]$ corresponding to the features $[1, 100]$, to compute the predicted output, we can simply take the dot product between them, so the output is $1*1 + 1*100 = 101$. Now, let's create the data with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0X6UmroKux0t"
   },
   "outputs": [],
   "source": [
    "(test_features, output) = get_numpy_data(data, ['Days'], 'People_tested')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task P2:** Complete the following function  'predict_output'. Copy the the outputs of the code to the solution file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9YpyW46tux0w"
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # Inputs:\n",
    "    # feature_matrix: a numpy matrix containing the features as columns (including the intercept), \n",
    "    #                 and each row corresponds to a data point\n",
    "    # weights: a numpy array for the corresponding regression weights (including the intercept)\n",
    "    # Output:\n",
    "    # a numpy array that contains the predicted outputs (according to the provided weights) \n",
    "    # for all the data points in the feature_matrix\n",
    " \n",
    "    # STUDENT: Start of code ####\n",
    "    \n",
    "    \n",
    "    return \n",
    "    ## end of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the outputs of this code to the solution file\n",
    "my_weights = np.array([1., 1.])\n",
    "test_predictions = predict_output(example_features, my_weights)\n",
    "print (\"(normalized) prediction at day 5: \", test_predictions[5]) \n",
    "print (\"(normalized) prediction at day 20 \", test_predictions[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the derivative of the regression cost function: \n",
    "$$L_D(w) = \\frac{1}{n}\\sum_{i=1}^n (y_i-w\\cdot x_i)^2,$$\n",
    "where $x_i\\in \\mathrm{R}^d$ is the input feature of dimension $d$, $y_i\\in\\mathrm{R}$ is the output response, and $w\\in\\mathrm{R}^d$ is the regression weights.\n",
    "\n",
    "**Task P3:** Complete the function 'weight_derivative' to calculate the derivative of the cost function with respect to regression weights $w$, i.e., $\\frac{\\partial}{\\partial w}L_D(w)$. Note that this should be a $d$ dimensional vector. Also copy the output of the code for the test example to the solution file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Xvp0delpux00"
   },
   "outputs": [],
   "source": [
    "def weight_derivative(weights, feature_matrix, labels):\n",
    "    # Input:\n",
    "    # weights: weight vector w, a numpy vector of dimension d\n",
    "    # feature_matrix: numpy array of size n by d, where n is the number of data points, and d is the feature dimension\n",
    "    # labels: true labels y, a numpy vector of dimension d\n",
    "    # Output:\n",
    "    # Derivative of the regression cost function with respect to the weight w, a numpy array of dimension d\n",
    "        \n",
    "    ## STUDENT: Start of code ###\n",
    "    \n",
    "    return\n",
    "    # End of code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Wlr5Agi4ux03",
    "outputId": "682c66f6-d3b2-4ce4-c378-75a3c32d71ab"
   },
   "outputs": [],
   "source": [
    "# NOTE: copy the output to the solution file.\n",
    "\n",
    "(example_features, example_output) = get_numpy_data(data, ['Days'], 'People_tested') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "derivative = weight_derivative(my_weights, example_features,example_output)\n",
    "\n",
    "print (derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will write a function to perform gradient descent algorithm on the lineare regression cost. Given an initial point, we will update the current weights by moving in the negative gradient direction to minimize the cost function. Thus, in each iteration we obtain the updated weight $w_{t+1}$ from the current iterate $w_t$ as follows:\n",
    "$$w_{t+1} = w_t - h\\frac{\\partial}{\\partial w}L_D(w_t),$$\n",
    "where $h$ is the 'step_size' that is the amount by which we move in the negative gradient direction. \n",
    "\n",
    "We stop when we are sufficiently close to the optimum (where gradient is the zero vector) by checking the condition with respect to the magnitude (length) of the gradient vector:\n",
    "$$\\|\\frac{\\partial}{\\partial w}L_D(w_t)\\|_2\\leq \\epsilon,$$\n",
    "where $\\epsilon$ is the 'tolerance' parameter.\n",
    "\n",
    "**Task P4:** Complete the code section to perform the gradient decent in the function `regression_gradient_descent`. Copy the code to the solution file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zo71SswVux1B"
   },
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, labels, initial_weights, step_size, tolerance):\n",
    "    # Gradient descent algorithm for linear regression problem    \n",
    "    \n",
    "    # Input:\n",
    "    # feature_matrix: numpy array of size n by d, where n is the number of data points, and d is the feature dimension\n",
    "    # labels: true labels y, a numpy vector of dimension d\n",
    "    # initial_weights: initial weight vector to start with, a numpy vector of dimension d\n",
    "    # step_size: step size of update\n",
    "    # tolerance: tolerace epsilon for stopping condition\n",
    "    # Output:\n",
    "    # Weights obtained after convergence\n",
    "\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # current iterate\n",
    "    i = 0\n",
    "    while not converged:\n",
    "        i += 1\n",
    "        # STUDENT: Start of code: your impelementation of what the gradient descent algorithm does in every iteration\n",
    "        # Refer back to the update rule listed above: update the weight\n",
    "        \n",
    "        \n",
    "        # Compute the gradient magnitude:\n",
    "        \n",
    "        gradient_magnitude = \n",
    "        \n",
    "        # Check the stopping condition to decide whether you want to stop the iterations\n",
    "        if              # STUDENT: check the stopping condition here\n",
    "            converged = True\n",
    "        \n",
    "        # End of code\n",
    "        \n",
    "        print (\"Iteration: \",i,\"gradient_magnitude: \", gradient_magnitude) # for us to check about convergence\n",
    "        \n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use gradient descent for linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the gradient descent algorithm for linear regression with a single feature ('Day'). Here we are using first 180 days' data as our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data\n",
    "train_data = data[:180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task P5:** Specify the initial_weights, step_size, and tolerance for the function `regression_gradient_descent`. Copy the outputs of the code to the solution file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Phah4z77ux1D"
   },
   "outputs": [],
   "source": [
    "simple_features = ['Days']\n",
    "my_output = 'People_tested'\n",
    "\n",
    "# Use get_numpy_data method to calculate the feature matrix and output. \n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "\n",
    "#Initialize the weights, step size and tolerance\n",
    "# Start of code\n",
    "#STUDENT: Specify the initial_weights, step_size, and tolerance\n",
    "initial_weights = \n",
    "step_size = \n",
    "tolerance = \n",
    "# end of code\n",
    "\n",
    "# Use the regression_gradient_descent function to calculate the gradient decent and store it in the variable 'final_weights'\n",
    "final_weights = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "\n",
    "# end of code\n",
    "print (\"Here are the final weights after convergence:\")\n",
    "print (final_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task P6:** Use the learned weights to predict 'People_tested' in the last three weeks in the dataset. Copy the predictions to the solution file, and calculate the test error\n",
    "$$\\frac{1}{n_{\\mathrm{tst}}}\\sum_{i=1}^{n_{\\mathrm{tst}}} (y_i^{\\mathrm{tst}}-\\hat{y}_i^{\\mathrm{tst}})^2,$$\n",
    "where $n_{\\mathrm{tst}}$ is the number of test data, $y_i^{\\mathrm{tst}}$ is the true label, $\\hat{y}_i^{\\mathrm{tst}}$ is the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test data\n",
    "test_data = data.iloc[-21:]\n",
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)\n",
    "test_predictions = predict_output(test_simple_feature_matrix, final_weights)\n",
    "print (test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the test error\n",
    "# STUDENT: Start of code\n",
    "\n",
    "\n",
    "#end of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will be considering multiple input features (`Intensive_care`,`New_positive_cases`,`Days`) to predict the `People_tested` in the future.\n",
    "\n",
    "**Task P7:** Specify the initial_weights, step_size, and tolerance for the function `regression_gradient_descent`. Print the outputs of the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLB46yGYwV6J"
   },
   "outputs": [],
   "source": [
    "model_features = ['Intensive_care','New_positive_cases','Days'] \n",
    "my_output = 'People_tested'\n",
    "\n",
    "#call the get_nupy_data method to calculate the feature matrix and output. Store them in the variables \"multi_feature_matrix\" & \"output\"\n",
    "\n",
    "(multi_feature_matrix, output) = get_numpy_data(data, model_features, my_output)\n",
    "\n",
    "# Initialize the weights, step size and tolerance\n",
    "# STUDENT: Start of code\n",
    "# STUDENT: Specify the initial_weights, step_size, and tolerance\n",
    "initial_weights = \n",
    "step_size = \n",
    "tolerance = \n",
    "# end of code\n",
    "weight_2 = regression_gradient_descent(multi_feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "print (\"Here are the final weights after convergence:\")\n",
    "print (weight_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task P8:** Use the learned weights to predict 'People_tested' in the last three weeks in the dataset.Find the value of the model predictions on the 10th day of the forecasting period.Also print the actual number of people tested on that particular day. Copy the predictions to the solution file, and calculate the test error. Note: here we are asking you to report the number before normalization. So you need to convert the prediction back to the unit of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "colab_type": "code",
    "id": "EjDMsSxtwWHY",
    "outputId": "b1d98d68-5301-4f1a-8fdc-0e2345714769"
   },
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "\n",
    "test_predictions_2 = predict_output(test_feature_matrix, weight_2)\n",
    "\n",
    "#Prediction for the 10th day of the forecasting period.\n",
    "print (test_predictions_2[10])\n",
    "\n",
    "#Convert the normalized data back to original figures using the same min-max normalization\n",
    "prediction_10th_day = test_predictions_2[10] * (data_orig['People_tested'].max() - data_orig['People_tested'].min()) + data_orig['People_tested'].min()\n",
    "\n",
    "print (\"Model prediction of the 10th day:\",int(prediction_10th_day))\n",
    "\n",
    "# Get the actual number of people tested from our test data on 10 th day of forecasting period.\n",
    "actual_people_tested = data_orig[\"People_tested\"].iloc[190]\n",
    "\n",
    "print (\"Actual number of people tested on the 10th day:\",actual_people_tested)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the test error\n",
    "# STUDENT: Start of code\n",
    "\n",
    "\n",
    "# end of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjMi9-rKux4y"
   },
   "source": [
    "# Explore on your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UyzUUzfOux4z"
   },
   "source": [
    "Now that you have tried two models for predictions, in this section, you can explore on your own an aspect of the problem that interests you. Here are some examples:\n",
    "* What features or what combination of features are most predictive for 'People_tested'?\n",
    "* How does tolerance for convergence affect prediction errors?\n",
    "* How does step size affect prediction errors?\n",
    "* How can we use validation to select the set of features to improve prediction?\n",
    "\n",
    "Report your question of investigation, as well as your results/interpretation in the solution file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QE7JK14Mux4z"
   },
   "outputs": [],
   "source": [
    "# Explore an aspect of the model that interests you\n",
    "### STUDENT: Start of code\n",
    "\n",
    "\n",
    "### End of code"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "linear_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
